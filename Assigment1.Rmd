---
title: "Assignment1:RMarkdown Homework"
author: "Süheyla Şeker"
date: "04/08/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

I am a senior industrial engineering student at Boğaziçi University. 
I like playing tennis and dancing. I am a Formula 1 fan.
My Linkedin profile is
[here](https://www.linkedin.com/in/suheylaseker/)

# UseR!2020:Doing Journalism with R (B. Witzenberger)
The presenter ***Benedict Witzenberger*** describes in the video how he is doing journalism by manipulating and visualizing data in R. He mentions that the proportion of the data they visualise in the stories is 12.1% and is increasing.***Witzenberger***, who works at the Süddeutsche Zeitung, said they received 98.7 million visitors at the digital in May due to the pandemic.The team retrieves the data from institutions such as DeStatis and the Robert Koch-Institut, as well as the leaked data from a dvd, usb or Aleph database.They conduct activities such as analysis of election results, identification of outliers, examination of leaked data, top and bottom points ,and tracking of changes over time through R.

[Doing Journalism with R](https://www.youtube.com/watch?v=1bmdHy5vtfY&list=LLOOXUVQ4VuNbQgs2jHR_2Hg&index=2&t=448s)



# Analyzing Formula 1 results in R 
***Thomas Hütter***, a Formula 1 fan like me, visualized the 2016 Formula 1 race results using R in his work. In this study, ***Thomas* Hütter*** aimed to compare the performance of pilots based on the scores they received in Formula 1 races in 2016, and filtered the race scores of the top 9 pilots to make it better to visualize the data because there is so much race data.Although ***Hütter*** used the data of 9 pilots to make the data easier to visualize, it became difficult to analyze all the data when he plotted it in a single chart using the **ggplot2** package. Each race driver's performance during the year has become more detailed in the graphics created separately, and  it was revealed that Nico Rosberg and Lewis Hamilton are the most stable pilots, as well as Daniel Ricciardo and Max Verstappen got at least 1 point at each race.

[Analyzing Formula 1 results in R](https://www.sqlservercentral.com/articles/analyzing-formula-1-results-in-r)

# Tennis Grand Slam Tournaments Champions Basic Analysis
***Giorgio Garziano***, an engineer and data scientist in Italy, studied Grand Slam men's championship data between 1877 and 2017, which he obtained from ESPN, one of the world's leading sports channels.This study aimed to determine whether there is an increase in the number of Grand slam champions over time, the probability of a player winning a grand slam more than a certain number, and the distribution of the number of grand slam winners. Using packages such as **extremevalues**, **dplyr**, **knitr** and **ggplot2** for data analysis ,***Garziano*** analyzed that there were 166 different Grand Slam winners in 141 years, with fewer Grand Slams being played in the first and second world wars. ***Garziano***, who first drew the data and then the log version of the data, then manipulated the data by showing the years the players last won a Grand Slam. ***Garziano***, who fit the data into the log normal distribution, has identified Roger Federer and Rafael Nadal as outliers. The author, who carried out regression analysis, said that as the present day approached, the number of new Grand Slam winners increased and there was a positive correlation between the number of new Grand Slam winners over time.

[Tennis Grand Slam Tournaments Champions Basic Analysis](https://www.sqlservercentral.com/articles/analyzing-formula-1-results-in-r)

# Scrape data from web pages
In this article, ***Kan Nashida*** explains how we can retrieve data from web pages that are not shared as files from csv,excel or other format. The **rvest** package makes it easy to extract data from websites that are also problematic in R, Phyton or other programming languages. One can use the rvest package to extract the data in a specific part of an html document. To do this, ***Nashida*** specifies that we can use the SelectorGadget chrome extension to extract the portion of data that we want to import in the html file. First we can use the **html_node()** and then **html_node()** functions to extract the data from the table and convert it to dataframe.



[Scrape data from web pages](https://blog.exploratory.io/scrape-data-from-web-pages-50e45b2b150a)



